{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5bf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PointNet\n",
    "Reference:\n",
    "https://github.com/yanx27/Pointnet_Pointnet2_pytorch/blob/master/models/pointnet_utils.py\n",
    "\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self, channel=3):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.iden = torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)).reshape(1, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = self.iden.repeat(batchsize, 1).to(x.device)\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "        self.iden = torch.from_numpy(np.eye(self.k).flatten().astype(np.float32)).reshape(1, self.k * self.k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = self.iden.repeat(batchsize, 1).to(x.device)\n",
    "\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"Encoder for PointNet\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 input_transform: bool=True,\n",
    "                 feature_transform: bool=True,\n",
    "                 is_seg: bool=False,  \n",
    "                 **kwargs\n",
    "                 ):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): feature size of input \n",
    "            input_transform (bool, optional): whether to use transformation for coordinates. Defaults to True.\n",
    "            feature_transform (bool, optional): whether to use transformation for features. Defaults to True.\n",
    "            is_seg (bool, optional): for segmentation or classification. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.stn = STN3d(in_channels) if input_transform else None\n",
    "        self.conv0_1 = torch.nn.Conv1d(in_channels, 64, 1)\n",
    "        self.conv0_2 = torch.nn.Conv1d(64, 64, 1)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(64, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn0_1 = nn.BatchNorm1d(64)\n",
    "        self.bn0_2 = nn.BatchNorm1d(64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fstn = STNkd(k=64) if feature_transform else None\n",
    "        self.out_channels = 1024 + 64 if is_seg else 1024 \n",
    "         \n",
    "    def forward_cls_feat(self, pos, x=None):\n",
    "        if hasattr(pos, 'keys'):\n",
    "            x = pos['x']\n",
    "        if x is None:\n",
    "            x = pos.transpose(1, 2).contiguous()\n",
    "        \n",
    "        B, D, N = x.size()\n",
    "        if self.stn is not None:\n",
    "            trans = self.stn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            if D > 3:\n",
    "                feature = x[:, :, 3:]\n",
    "                x = x[:, :, :3]\n",
    "            x = torch.bmm(x, trans)\n",
    "            if D > 3:\n",
    "                x = torch.cat([x, feature], dim=2)\n",
    "            x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn0_1(self.conv0_1(x)))\n",
    "        x = F.relu(self.bn0_2(self.conv0_2(x)))\n",
    "\n",
    "        if self.fstn is not None:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        return x\n",
    "\n",
    "    def forward_seg_feat(self, pos, x=None):\n",
    "        if hasattr(pos, 'keys'):\n",
    "            x = pos.get('x', None)\n",
    "        if x is None:\n",
    "            x = pos.transpose(1, 2).contiguous()\n",
    "\n",
    "        B, D, N = x.size()\n",
    "        if self.stn is not None:\n",
    "            trans = self.stn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            if D > 3:\n",
    "                feature = x[:, :, 3:]\n",
    "                x = x[:, :, :3]\n",
    "            x = torch.bmm(x, trans)\n",
    "            if D > 3:\n",
    "                x = torch.cat([x, feature], dim=2)\n",
    "            x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn0_1(self.conv0_1(x)))\n",
    "        x = F.relu(self.bn0_2(self.conv0_2(x)))\n",
    "\n",
    "        if self.fstn is not None:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024, 1).repeat(1, 1, N)\n",
    "        return pos, torch.cat([pointfeat, x], 1)\n",
    "    \n",
    "    def forward(self, x, features=None):\n",
    "        return self.forward_cls_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf5a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNetEncoder(\n",
       "  (stn): STN3d(\n",
       "    (conv1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv0_1): Conv1d(4, 64, kernel_size=(1,), stride=(1,))\n",
       "  (conv0_2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "  (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "  (bn0_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn0_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fstn): STNkd(\n",
       "    (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"./pre-trained/pointnet_pre_trainder.pth\", map_location=\"cuda\")\n",
    "state_dict = checkpoint['model']\n",
    "\n",
    "# Strip \"encoder.\" prefix and ignore classifier weights\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith(\"encoder.\"):\n",
    "        new_key = k[len(\"encoder.\"):]  # remove prefix\n",
    "        new_state_dict[new_key] = v\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = PointNetEncoder(in_channels=4)\n",
    "\n",
    "# Load filtered state_dict\n",
    "encoder.load_state_dict(new_state_dict)\n",
    "encoder.eval()\n",
    "encoder.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6011f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 15])\n",
      "Output: tensor([[-0.0148,  0.0100,  0.0501,  0.0233, -0.0017,  0.0111, -0.0213,  0.0035,\n",
      "         -0.0051,  0.0198, -0.0114,  0.0101, -0.0501, -0.0183, -0.0177],\n",
      "        [-0.0154,  0.0077,  0.0513,  0.0231, -0.0014,  0.0109, -0.0223,  0.0045,\n",
      "         -0.0048,  0.0187, -0.0084,  0.0122, -0.0494, -0.0183, -0.0180],\n",
      "        [-0.0156,  0.0080,  0.0508,  0.0236, -0.0035,  0.0103, -0.0226,  0.0065,\n",
      "         -0.0035,  0.0197, -0.0093,  0.0097, -0.0519, -0.0178, -0.0179],\n",
      "        [-0.0180,  0.0073,  0.0485,  0.0217, -0.0018,  0.0135, -0.0235,  0.0046,\n",
      "         -0.0047,  0.0175, -0.0099,  0.0080, -0.0491, -0.0173, -0.0177],\n",
      "        [-0.0160,  0.0076,  0.0483,  0.0227, -0.0017,  0.0117, -0.0213,  0.0040,\n",
      "         -0.0036,  0.0179, -0.0108,  0.0086, -0.0477, -0.0190, -0.0193],\n",
      "        [-0.0178,  0.0092,  0.0512,  0.0226, -0.0030,  0.0123, -0.0247,  0.0071,\n",
      "         -0.0035,  0.0180, -0.0103,  0.0115, -0.0489, -0.0193, -0.0166],\n",
      "        [-0.0153,  0.0074,  0.0503,  0.0211, -0.0014,  0.0096, -0.0218,  0.0059,\n",
      "         -0.0051,  0.0173, -0.0118,  0.0112, -0.0503, -0.0197, -0.0172],\n",
      "        [-0.0152,  0.0095,  0.0492,  0.0215, -0.0012,  0.0083, -0.0230,  0.0052,\n",
      "         -0.0054,  0.0181, -0.0101,  0.0103, -0.0505, -0.0201, -0.0183]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Make sure your encoder is loaded\n",
    "encoder = PointNetEncoder(in_channels=4)\n",
    "encoder.eval()\n",
    "encoder.to(\"cuda\")\n",
    "\n",
    "# Simple classifier head\n",
    "num_classes = 15\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "# Wrapper to combine encoder + classifier\n",
    "# Wrapper to combine encoder + classifier\n",
    "class PointNetWithHead(nn.Module):\n",
    "    def __init__(self, encoder, classifier):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass x as B,C,N and avoid automatic transpose\n",
    "        features = self.encoder.forward_cls_feat(x, x=x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = PointNetWithHead(encoder, classifier)\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Generate some artificial point cloud data\n",
    "B, C, N = 8, 4, 1024\n",
    "fake_data = torch.randn(B, C, N).cuda()\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(fake_data)\n",
    "\n",
    "print(\"Output shape:\", outputs.shape)  # should be (B, num_classes)\n",
    "print(\"Output:\", outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303b52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class ConeClusterDataset(Dataset):\n",
    "    def __init__(self, json_files, num_points=128):\n",
    "        \"\"\"\n",
    "        json_files: list of paths to your JSON cluster files\n",
    "        num_points: fixed number of points per cluster\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.num_points = num_points\n",
    "\n",
    "        for file_path in json_files:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            for frame in data.values():\n",
    "                for cluster in frame['clusters']:\n",
    "                    points = cluster['points']\n",
    "                    label = cluster['label']\n",
    "                    if label == 255:\n",
    "                        label=0\n",
    "                    self.samples.append((points, label))\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        points, label = self.samples[idx]\n",
    "\n",
    "        # Convert to numpy array (N, 4) [x, y, z, intensity]\n",
    "        pts = np.array([[p['x'], p['y'], p['z'], p['i']] for p in points], dtype=np.float32)\n",
    "        \n",
    "        # Normalize coordinates relative to centroid\n",
    "        centroid = pts[:, :3].mean(axis=0, keepdims=True)  # (1,3)\n",
    "        pts[:, :3] -= centroid\n",
    "\n",
    "        # Normalize intensity\n",
    "        pts[:, 3] /= 255.0\n",
    "\n",
    "        # Downsample or pad\n",
    "        N = pts.shape[0]\n",
    "        if N >= self.num_points:\n",
    "            choice = np.random.choice(N, self.num_points, replace=False)\n",
    "            pts = pts[choice]\n",
    "        else:\n",
    "            pad = np.zeros((self.num_points - N, pts.shape[1]), dtype=np.float32)\n",
    "            pts = np.vstack([pts, pad])\n",
    "\n",
    "        # Transpose to (features, points) for PointNet\n",
    "        return torch.tensor(pts, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94091c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = ConeClusterDataset([\"../data/fsg_accel_2024_08_16-11_06_03_recovered_filtered_0_labels.json\", \"../data/skidpad_2025-08-06-17_26_12_merged_filtered_0_labels.json\"], num_points=128)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b989e8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7318, Accuracy: 0.7347\n",
      "Epoch 2/5, Loss: 0.5335, Accuracy: 0.8109\n",
      "Epoch 3/5, Loss: 0.4876, Accuracy: 0.8262\n",
      "Epoch 4/5, Loss: 0.4569, Accuracy: 0.8383\n",
      "Epoch 5/5, Loss: 0.4487, Accuracy: 0.8401\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Assume PointNetEncoder and ConeClusterDataset are defined as before\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load Pretrained Encoder\n",
    "# ----------------------------\n",
    "encoder = PointNetEncoder(in_channels=4)  # 4 channels: x, y, z, intensity\n",
    "checkpoint = torch.load(\"../models/pre-trained/pointnet_pre_trainder.pth\", map_location=\"cpu\")\n",
    "state_dict = checkpoint['model']\n",
    "\n",
    "# Remove the 'encoder.' prefix from keys if present\n",
    "new_state_dict = {k.replace(\"encoder.\", \"\"): v for k, v in state_dict.items() if \"prediction\" not in k}\n",
    "encoder.load_state_dict(new_state_dict, strict=False)\n",
    "encoder.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Add a classifier head\n",
    "# ----------------------------\n",
    "num_classes = 4  # adjust to your labels\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, num_classes)\n",
    ")\n",
    "\n",
    "class PointNetWithHead(nn.Module):\n",
    "    def __init__(self, encoder, classifier):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.encoder.forward_cls_feat(x)  # get global features\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "\n",
    "model = PointNetWithHead(encoder, classifier)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Prepare Dataset & Dataloader\n",
    "# ----------------------------\n",
    "train_files = [\"../data/fsg_accel_2024_08_16-11_06_03_recovered_filtered_0_labels.json\", \"../data/skidpad_2025-08-06-17_26_12_merged_filtered_0_labels.json\"]  # replace with your paths\n",
    "train_dataset = ConeClusterDataset(train_files, num_points=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Training Setup\n",
    "# ----------------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Training Loop\n",
    "# ----------------------------\n",
    "num_epochs = 5\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
